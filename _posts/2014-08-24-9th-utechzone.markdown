---
title: The 9​th​ Utechzone Machine Vision Prize
subtitle: Sense by Computer Vision
layout: default
modal-id: 8
date: 2014-08-24
thumbnail: 9th_utechzone/result.jpg
project-date: Feb. - Aug. 2014
keyword: Motion detection, Image segmentation
---
<!-- Sample Consesus Method (Wang and Suter, 2006) -->

<a href="http://www.utechzone.com.tw/" target="_blank">Utechzone Co.,LTD</a> is a well-known technical company aimed at machine vision technology and dedicated to the development of automated machine vision systems in Taiwan. The Utechone Machine Vision Prize has been held by the company since 2006 in order to encourage the development of computer vision. The labmates and I represented the <a href="http://ttlin.bime.ntu.edu.tw/ttlin/" target="_blank">Biophotonics and Bioimaging Laboratory</a> to participate in this competition and won the **2<sup>nd</sup> prize**.

This competition, different from before that's used to aim at face recognition, is focused on three subjects: fall detection, left object detection and phone detection. I will focus on the fall detection part which I was in charge of. In order to detect the fall motion which is a continuous action, the information of objects must be recorded continuously.

![Flowchart]({{ site.url }}/img/portfolio/9th_utechzone/fall-flowchart.jpg)

First, due to the fixed field of view of camera, the SAmple CONsensus (SACON) method (Wang and Suter, 2006) was implemented to extract the foreground by subtracting a background generated by unchanged pixels. The foreground was then processed using erosion and dilation to filter out the noises. The detected objects were tracking using Kalman filter.

| ![Origin]({{ site.url }}/img/portfolio/9th_utechzone/3_origin.jpg) | ![Modeled background]({{ site.url }}/img/portfolio/9th_utechzone/3_bg_bguilt.jpg) |
|:------:|:----------------:|
| **Origin** | **Built Background** |
| ![Processed foreground]({{ site.url }}/img/portfolio/9th_utechzone/3_fg_ED.jpg) | ![Outcome]({{ site.url }}/img/portfolio/9th_utechzone/3_blob.jpg) |
| **Processed Foreground** | **Detected Result** |

The geometrical features, such as an aspect ratio of the region of interest (ROI), a cetroid of the ROI, and a histogram of pixels in the ROI, were applied to determine the fall motion. For instance, when the aspect ratio drastically changed and the centroid position was lower than before, the motion would be identied as possible fall motion.

<br>

![Motion detection]({{ site.url }}/img/portfolio/9th_utechzone/fall-motion.jpg)

<br>

![Certificate]({{ site.url }}/img/portfolio/9th_utechzone/14UTMVP.JPG)